<html lang ="es">
<head>
       <link type="text/css"rel="stylesheet"  href="../CSS/formato.css">
       <meta charset ="UTF-8">
       <meta name ="viewport" content ="width=device-width,initial-scale=1.0">
       <meta http-equiv="X-UA-Compatible" content="ie=edge">
	 <title> Arquitectura de Computadoras</title>
		<link rel="shortcut icon" href ="../IMG/img1.png" type="image/x-icon">

<link rel = "preconnect" href = "https://fonts.googleapis.com">
<link rel = "preconnect" href = "https://fonts.gstatic.com" crossorigin>
<link href = "https: //fonts.googleapis.com/css2? family = Libre + Baskerville: wght @ 700 & display = swap "rel =" stylesheet ">
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Libre+Baskerville:wght@400;700&display=swap" rel="stylesheet">
</head>


<body class="fondo">
<p class="titulo">
 Temario 
</p>
<p class="titulo"><marquee><font color="Yellow">
 Arquitectura de Computadoras</font></marquee>
</p>

<div class="menu">

<ul class ="menuU">

<p>Unidadades</p>
</li>                          
<li><a href="../HTML/index.html"><font color="teal">Unidad 1 </a></font>
</li>
<li><a href="../HTML/unidad2.html"><font color="fuchsia">Unidad 2 </a></font>
                                  
</li>
<li><a href="../HTML/unidad3.html"><font color="purple">Unidad 3 </a></font>
</li>
<li><a href="../HTML/unidad4.html"><font color="yellow">Unidad 4 </a></font>
</li>
<li><a href="../HTML/actividades.html"><font color="green">Actividades </a></font>
 </li>
</ul>                 
</div>


<div class="op">

 <ul class ="contenidocuadro">
                          
                                 <p class="cont">Contenido </p>
                        <div class="verticalLine">
                                              
                               </div>
                          <li><a href="">4.1 Aspectos Basicos de la Computaciòn Paralela. </a></li>
                         <ul> 
                                  
                             </ul>
                              </li>

                             <li><a href="">4.2 Tipos de Computacion Paralela. </a></li>
                         <ul> 
                                  <li><a href="">4.2.1 Clasificaciòn </a></li>
                                   <li><a href="">4.2.2 Arquitectura de Computadores Secuenciales.</a></li>
                                    <li><a href="">4.2.3 Organizaciòn de direcciones de memoria</a></li>
                              </ul>
                              </li>
                                 
                             <li><a href="">4.3 Sistemas de memoria (compartida) Multiprocesadores. </a></li>
                         <ul> 
                                  <li><a href="">4.3.1 Redes de interconexion dinamica (indirecta)</a></li>
                                   <li><a href="">4.3.2 Medio Compartido.</a></li>
                                    <li><a href="">4.3.3 Conmutadas</a></li>
                                 
                                    
                              </ul>
                              </li>
                               
                                <li><a href="">4.4 Sistemas de memoria distribuida. </a></li>
                         <ul> 
                                  <li><a href="">4.4.1 Multicomputadores</a></li>
                                   <li><a href="">4.4.2 Redes de Interconexion Estaticas.</a></li>
                                    
                              </ul>
                              </li>
                                  <li><a href="">4.5 Casos Para estudio </a></li>
                         
                              </li>

</div>

<div class="op2">
<p class ="unidaduno">
	Unidad 4 - Arquitecturas de cómputo
</p>
<p class ="unidadunouno">
	4.1 Aspectos Basicos de la Computaciòn Paralela.

	</p>
<p class ="in">
La computación paralela es una forma de cómputo en la que muchas instrucciones se ejecutan simultáneamente, operando sobre
el principio de que problemas grandes, a menudo se pueden dividir en unos más pequeños, que luego son resueltos simultáneamente
(en paralelo). Hay varias formas diferentes de computación paralela: paralelismo a nivel de bit, paralelismo a nivel de
instrucción, paralelismo de datos y paralelismo de tareas. El paralelismo se ha empleado durante muchos años, sobre todo
en la computación de altas prestaciones, pero el interés en ella ha crecido últimamente debido a las limitaciones físicas
que impiden el aumento de la frecuencia. Como el consumo de energía y por consiguiente la generación de calor de las
computadoras constituye una preocupación en los últimos años, la computación en paralelo se ha convertido en el paradigma
dominante en la arquitectura de computadores, principalmente en forma de procesadores multinúcleo.
</p>
<p class ="in">
Las computadoras paralelas pueden clasificarse según el nivel de paralelismo que admite su hardware: equipos con procesadores
multinúcleo y multi-procesador que tienen múltiples elementos de procesamiento dentro de una sola máquina y los clústeres,
MPPS y grids que utilizan varios equipos para trabajar en la misma tarea. Muchas veces, para acelerar la tareas específicas,
se utilizan arquitecturas especializadas de computación en paralelo junto a procesadores tradicionales
</p>

<p class ="unidadunouno">
	4.2 Tipos de computación paralela

	</p>
<p class ="titulo2">
	Paralelismo a nivel de bit

	</p>

<p class ="in">
Desde el advenimiento de la integración a gran escala (VLSI) como tecnología de fabricación de chips de computadora en la
década de 1970 hasta alrededor de 1986, la aceleración en la arquitectura de computadores se lograba en gran medida duplicando
el tamaño de la palabra en la computadora, la cantidad de información que el procesador puede manejar por ciclo.
</p>
<p class ="titulo2">
	Paralelismo a nivel de instrucción

	</p>

<p class ="in">
Un programa de ordenador es, en esencia, una secuencia de instrucciones ejecutadas por un procesador. Estas instrucciones
pueden reordenarse y combinarse en grupos que luego son ejecutadas en paralelo sin cambiar el resultado del programa. Esto
se conoce como paralelismo a nivel de instrucción. Los avances en el paralelismo a nivel de instrucción dominaron la
arquitectura de computadores desde mediados de 1980 hasta mediados de la década de 1990.
</p>
<p class ="in">
Los procesadores modernos tienen ''pipeline'' de instrucciones de varias etapas. Cada etapa en el pipeline corresponde a
una acción diferente que el procesador realiza en la instrucción correspondiente a la etapa; un procesador con un pipelinede
N etapas puede tener hasta n instrucciones diferentes en diferentes etapas de finalización. El ejemplo canónico de un procesador
segmentado es un procesador RISC, con cinco etapas: pedir instrucción, decodificar, ejecutar, acceso a la memoria y escritura.
El procesador Pentium 4 tenía un pipeline de 35 etapas.
</p>
<img class="ins">

<p class ="titulo2">
	Paralelismo de datos:

	</p>

<p class ="in">
El paralelismo de datos es el paralelismo inherente en programas con ciclos, que se centra en la distribución de los datos
entre los diferentes nodos computacionales que deben tratarse en paralelo. La paralelización de ciclos conduce a menudo a
secuencias similares de operaciones —no necesariamente idénticas— o funciones que se realizan en los elementos de una gran
estructura de datos. Muchas de las aplicaciones científicas y de ingeniería muestran paralelismo de datos.
</p>
<p class ="in">
Una dependencia de terminación de ciclo es la dependencia de una iteración de un ciclo en la salida de una o más iteraciones
anteriores. Las dependencias de terminación de ciclo evitan la paralelización de ciclos.
</p>
<p class ="titulo2">
	Paralelismo de tareas:

	</p>

<p class ="in">
El paralelismo de tareas es la característica de un programa paralelo en la que cálculos completamente diferentes se pueden
realizar en cualquier conjunto igual o diferente de datos. Esto contrasta con el paralelismo de datos, donde se realiza el
mismo cálculo en distintos o mismos grupos de datos. El paralelismo de tareas por lo general no escala con el tamaño de un
problema.
</p>

<p class ="unidadunouno">
	4.2.1 Clasificación

	</p>
<p class ="titulo2">
	Taxonomía de las Computadoras
	</p>
<p class ="in">
Las diferentes posibilidades existentes para desarrollar sistemas paralelos hacen que una clasificación definitiva sea
complicada. Se muestra una clasificación clásica propuesta por Flynn, que se basa en el ciclo de instrucciones y en el
flujo de dato.
</p>
<p class ="titulo2">
	Taxonomía de FLYNN
	</p>
<p class ="in">
En 1966 Flynn propuso una clasificación generalista de las computadoras adoptando como criterio el flujo de instrucciones y
el flujo de datos que en ellos se desarrolla. La clasificación de Flynn es la siguiente:
</p>

<ul class ="viñetas">
<li>SISD:
 SISD:
Instrucción única, datos únicos. Las instrucciones se ejecutan secuencialmente pero pueden estar solapadas
en las etapas de ejecución.
</li>
<li>SIMD:
 Instrucción única, datos múltiples. Son los procesadores matriciales en los que existen varias unidades
de procesamiento trabajando sobre flujos de datos distintos pero ejecutando la misma instrucción.
</li>
<li>MISD: Instrucción múltiple, datos únicos. Este se caracteriza por la existencia de varias unidades de procesamiento cada una
ejecutando una instrucción diferente pero sobre el mismo flujo de datos. </li>
<li>MIMD:
Es una técnica empleada para lograr paralelismo. Las máquinas que usan MIMD tienen un número de procesadores que funcionan
de manera asíncrona e independiente.
</li>
</ul>

<p class ="unidadunouno">
	4.2.2 Arquitectura de computadores secuenciales
	</p>
<p class ="in">
Elementos
</p>
<ul class ="viñetas">
<li>Un conjunto finito, n, de variables de entrada (X1, X2,..., Xn).</li>
<li>Un conjunto finito, m, de estados internos, de aquí que los estados secuenciales también sean denominados autómatas finitos. Estos estados proporcionarán m variables internas (Y1,Y2,..., Ym).</li>
<li>Un conjunto finito, p, de funciones de salida (Z1, Z2,..., Zp).</li>
</ul>
<img class="sec">

<p class ="unidadunouno">
	4.2.3 Organizaciòn de direcciones de memoria
	</p>
<p class ="in">
La memoria principal en un ordenador en paralelo puede ser compartida —compartida entre todos los elementos de procesamiento en un único espacio de direcciones—, o distribuida —cada elemento de procesamiento tiene su propio espacio local de direcciones—. ​El término memoria distribuida se refiere al hecho de que la memoria se distribuye lógicamente, pero a menudo implica que también se distribuyen físicamente. La memoria distribuida-compartida y la virtualización de memoria combinan los dos enfoques, donde el procesador tiene su propia memoria local y permite acceso a la memoria de los procesadores que no son locales. Los accesos a la memoria local suelen ser más rápidos que los accesos a memoria no local.
</p>
<p class ="in">
Las arquitecturas de ordenador en las que cada elemento de la memoria principal se puede acceder con igual latencia y ancho de banda son conocidas como arquitecturas de acceso uniforme a memoria (UMA). Típicamente, sólo se puede lograr con un sistema de memoria compartida, donde la memoria no está distribuida físicamente. Un sistema que no tiene esta propiedad se conoce como arquitectura de acceso a memoria no uniforme (NUMA). Los sistemas de memoria distribuidos tienen acceso no uniforme a la memoria
</p>
<p class ="unidadunouno">
	4.3 Sistemas de memoria compartida (multiprocesadores)
	</p>
<p class ="in">
La mayoría de los multiprocesadores comerciales son del tipo UMA (Uniform Memory Access): todos los procesadores tienen igual tiempo de acceso a la memoria compartida. En la arquitectura UMA los procesadores se conectan a la memoria a través de un bus, una red multietapa o un conmutador de barras cruzadas (red multietapa o un conmutador de barras cruzadas (crossbar crossbar) y disponen de su propia ) y disponen de su propia memoria caché. Los procesadores tipo NUMA (Non Uniform Memory Access) presentan tiempos de acceso a la memoria compartida que dependen de la ubicación del elemento de proceso y la memoria
</p>
<img class="mult">
<p class ="unidadunouno">
	4.3.1 Redes de interconexión dinámica (indirecta)
	</p>
<p class ="in">
Uno de los criterios más importantes para la clasificación de las redes es el que tiene en cuenta la situación de la red
en la máquina paralela, dando lugar a dos familias de redes: redes estáticas y redes dinámicas. Una red estática es una
red cuya topología queda definida de manera definitiva y estable durante la construcción de la máquina paralela.
</p>


<p class ="unidadunouno">
	4.3.2 Medio Compartido.

	</p>
<p class ="in">
En el ejemplo del subapartado anterior sólo había un emisor y un receptor unidos por una fibra óptica. En el mundo de las
comunicaciones, y de las redes de computadores en particular, el medio que se utiliza para comunicarse suele estar compartido.
Con una serie de ejemplos iremos viendo diferentes maneras de compartir el medio.

En el caso de la televisión o la radio, existen diferentes canales y emisoras que están compartiendo el medio. A fin de que
no haya problemas, hay una regulación del espectro radioeléctrico: se tiene cuidado de que cada uno de los canales tenga
asignada una frecuencia determinada y que no haya más de un canal usando la misma frecuencia. Este sistema se llama
multiplexación por división de frecuencia y no sólo se utiliza en la radio y la televisión.
</p>

<p class ="unidadunouno">
	4.3.3 Conmutadas

	</p>
<p class ="in">
Cuando se va a enviar datos a largas distancias (e incluso a no tan largas), este debe pasar por varios nodos intermedios.
Los cuáles son los encargados de dirigir los datos para que lleguen a su destino. Por lo cual se hace uso de lo que es una
red conmutada. ya que estas Consisten en un conjunto de nodos interconectados entre sí, a través de medios de transmisión,
formando así la mayoría de las veces una topología mallada, donde la información se traslada encaminándola del nodo de origen
al nodo destino mediante conmutación entre nodos intermedios.
</p>


<p class ="unidadunouno">
	4.3.4 Sistemas de memoria distribuida (multicomputadores)

	</p>
<p class ="in">
Los sistemas de memoria distribuida o multicomputadores pueden ser de dos tipos básicos. El primer de ellos consta de un
único computador con múltiples CPUs comunicadas por un bus de datos mientras que en el segundo se utilizan múltiples
computadores, cada uno con su propio procesador, enlazados por una red de interconexión más o menos rápida.
</p>

<p class ="in">
Sobre los sistemas de multicomputadores de memoria distribuida, se simula memorias compartidas. Se usan los mecanismos
de comunicación y sincronización de sistemas multiprocesadores.
</p>

<p class ="in">
Un clúster es un tipo de arquitectura paralela distribuida que consiste de un conjunto de computadores independientes
interconectados operando de forma conjunta como único recurso computacional sin embargo, cada computador puede utilizarse
de forma independiente o separada.
</p>

<p class ="unidadunouno">
	4.4.1 Redes de interconexión estáticas

	</p>

<p class ="in">
Las redes estáticas emplean enlaces directos fijos entre los nodos. Estos enlaces, una vez fabricado el sistema son
difíciles de cambiar, por lo que la escalabilidad de estas topologías es baja. Las redes estáticas pueden utilizarse
con eficiencia en los sistemas en que pueden predecirse el tipo de tráfico de comunicaciones entre sus procesadores.
</p>

<p class ="unidadunouno">
	4.5 Casos Para estudio 

	</p>
<p class ="in">
Ejemplos de caso de estudio:
</p>
<p class ="in">
1. NVIDIA PYSICS LAYER: GPU PhysXCPU PhysXGraphics Layer: GPU –Direct X Windows
</p>
<p class ="in">
2. INTELPYSICS LAYER:No GPU PhysXCPU HavokGraphics Layer:GPU –Direct XWindows
</p>
<p class ="in">
3. AMD PYSICS LAYER: No GPU PhysXCPU HavokGraphics Layer:GPU –Direct XWindows
</p>
<p class ="in">
nteresa realizar investigación en la especificación, transformación, optimización y evaluación de algoritmos
distribuidos y paralelos. Esto incluye el diseño y desarrollo de sistemas paralelos, la transformación de
algoritmos secuenciales en paralelos, y las métricas de evaluación de performance sobre distintas plataformas
de soporte (hardware y software). Más allá de las mejoras constantes en las arquitecturas físicas de soporte,
uno de los mayores desafíos se centra en cómo aprovechar al máximo la potencia de las mismas
</p>





</div>
</body>